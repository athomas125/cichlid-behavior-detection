import deeplabcut as dlc
from behavior_detection.misc import analyse_videos
from behavior_detection.misc.train_network import kill_and_reset

def main():
    config_path = '/data/home/athomas314/dlc_model-student-2023-07-26/config.yaml'

    # for testing zero shot
    # config_path = '/data/home/athomas314/dlc_model-student-zero-shot-yellowhead/config.yaml'

    # config_path = '/data/home/athomas314/YellowHeadCroppedVid1-Adam-2024-05-29/config.yaml'

    dlc.create_multianimaltraining_dataset(config_path)

    dlc.train_network(config_path, shuffle=1, gputouse=1, saveiters=10000, maxiters=100000)
    dlc.evaluate_network(config_path, gputouse=2)
    
    video_path = ['/data/home/athomas314/test_video/MC_singlenuc23_1_Tk33_0212200003_vid_clip_36170_38240.mp4']
    for video in video_path:
            try:
                analyse_videos(config_path=config_path, videos=[video], shuffle=1, n_fish=10)
            except Exception:
                kill_and_reset()
                continue

    # # Analyse videos must be run before doing transformer reidentification and the transformer re-id 
    # # uses the bodypart embeddings (generated by analyse_videos) + tracks as it's inputs.
    dlc.transformer_reID(config_path, video_path)
    
    # this only works right now for my personal modified version version of deeplabcut 
    # TODO - create a standalone version of create video method to do this.
    dlc.create_labeled_video(config_path, 
                             video_path, 
                             shuffle=1,
                             filtered=True,
                             color_by="individual",
                             overwrite=True,
                             use_transf_labels=True,
                             plot_with_center_trail=True,
                             center_trailpoints=90
                             )
    # dlc.plot_trajectories(config_path, video_path, shuffle=1)
    
if __name__ == "__main__":
    main()